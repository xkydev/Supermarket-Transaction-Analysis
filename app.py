"""
Aplicaci√≥n principal de Streamlit para an√°lisis de transacciones de supermercado.
"""

import sys
from pathlib import Path
import logging
from typing import Optional
import shutil

import streamlit as st
import pandas as pd
import plotly.express as px

# Agregar el directorio ra√≠z al path
sys.path.insert(0, str(Path(__file__).parent))

from src.data_loader import DataLoader
from src.data_processor import DataProcessor
from src.metrics import MetricsCalculator
from src.visualizations import Visualizer
from src.clustering import CustomerSegmentation
from src.recommender import RecommenderSystem
from config import Paths, ClusteringConfig, VisualizationConfig, RecommenderConfig

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============================================================================
# FUNCIONES CACHEADAS PARA SISTEMA DE RECOMENDACIONES
# ============================================================================

@st.cache_data(ttl=3600, show_spinner="üîó Generando reglas de asociaci√≥n...")
def build_cached_association_rules(
    _transactions_df,
    min_support: float,
    min_confidence: float,
    min_lift: float,
    max_transactions: Optional[int] = None
):
    """Construye y cachea las reglas de asociaci√≥n de Apriori.
    
    Args:
        _transactions_df: DataFrame de transacciones
        min_support: Soporte m√≠nimo
        min_confidence: Confianza m√≠nima
        min_lift: Lift m√≠nimo
        max_transactions: M√°ximo de transacciones a analizar
    
    Returns:
        DataFrame con reglas de asociaci√≥n
    """
    recommender = RecommenderSystem()
    rules = recommender.build_association_rules(
        transactions_df=_transactions_df,
        min_support=min_support,
        min_confidence=min_confidence,
        min_lift=min_lift,
        max_transactions=max_transactions
    )
    return rules


@st.cache_data(ttl=1800, show_spinner="üéØ Calculando recomendaciones...")
def get_cached_customer_recommendations(
    customer_id: int,
    _transactions_df,
    top_n: int = 10,
    top_k_similar: int = 1000,
    min_similarity: float = 0.1
):
    """Obtiene recomendaciones para un cliente usando cach√©.
    
    Args:
        customer_id: ID del cliente
        _transactions_df: DataFrame de transacciones
        top_n: N√∫mero de recomendaciones
        top_k_similar: N√∫mero de clientes similares a considerar
        min_similarity: Similitud m√≠nima
    
    Returns:
        DataFrame con recomendaciones
    """
    recommender = RecommenderSystem()
    recommendations = recommender.get_customer_recommendations(
        customer_id=customer_id,
        transactions_df=_transactions_df,
        top_n=top_n,
        top_k_similar=top_k_similar,
        min_similarity=min_similarity
    )
    return recommendations


@st.cache_data(ttl=1800, show_spinner="üéØ Calculando recomendaciones de productos...")
def get_cached_product_recommendations(
    product_id: int,
    _association_rules,
    _transactions_df,
    top_n: int = 10
):
    """Obtiene recomendaciones para un producto usando reglas cacheadas.
    
    Args:
        product_id: ID del producto
        _association_rules: DataFrame con reglas de asociaci√≥n
        _transactions_df: DataFrame de transacciones
        top_n: N√∫mero de recomendaciones
    
    Returns:
        DataFrame con recomendaciones
    """
    recommender = RecommenderSystem()
    # Filtrar reglas donde el producto est√° en el antecedente
    product_rules = _association_rules[
        _association_rules['antecedents'].apply(lambda x: product_id in x)
    ].copy()
    
    if product_rules.empty:
        return pd.DataFrame()
    
    # Extraer productos recomendados del consecuente
    recommendations = []
    for _, rule in product_rules.iterrows():
        for consequent_id in rule['consequents']:
            if consequent_id != product_id:
                recommendations.append({
                    'product_id': consequent_id,
                    'support': rule['support'],
                    'confidence': rule['confidence'],
                    'lift': rule['lift']
                })
    
    if not recommendations:
        return pd.DataFrame()
    
    # Convertir a DataFrame y agregar por producto
    recommendations_df = pd.DataFrame(recommendations)
    recommendations_df = recommendations_df.groupby('product_id').agg({
        'support': 'mean',
        'confidence': 'max',
        'lift': 'max'
    }).reset_index()
    
    # Ordenar por lift y tomar top N
    recommendations_df = recommendations_df.sort_values('lift', ascending=False).head(top_n)
    
    # Enriquecer con informaci√≥n del producto
    # Verificar qu√© columnas est√°n disponibles
    available_columns = ['product_id']
    if 'product_name' in _transactions_df.columns:
        available_columns.append('product_name')
    if 'category_name' in _transactions_df.columns:
        available_columns.append('category_name')
    
    product_info = _transactions_df[available_columns].drop_duplicates(subset=['product_id'])
    recommendations_df = recommendations_df.merge(product_info, on='product_id', how='left')
    
    # Generar nombres si no existen
    if 'product_name' not in recommendations_df.columns:
        recommendations_df['product_name'] = recommendations_df['product_id'].apply(lambda x: f"Producto {x}")
    if 'category_name' not in recommendations_df.columns:
        recommendations_df['category_name'] = "Sin categor√≠a"
    
    # Calcular score (combinaci√≥n de lift, confidence y support)
    recommendations_df['score'] = (
        recommendations_df['lift'] * 0.5 +
        recommendations_df['confidence'] * 100 * 0.3 +
        recommendations_df['support'] * 100 * 0.2
    )
    
    return recommendations_df


@st.cache_data
def load_processed_data():
    """Carga los datos procesados desde CSV."""
    transactions = pd.read_csv(Paths.DATA_PROCESSED / 'transactions_expanded.csv')
    customer_metrics = pd.read_csv(Paths.DATA_PROCESSED / 'customer_metrics.csv')
    product_metrics = pd.read_csv(Paths.DATA_PROCESSED / 'product_metrics.csv')
    transaction_metrics = pd.read_csv(Paths.DATA_PROCESSED / 'transaction_metrics.csv')
    
    # Convertir fechas
    transactions['date'] = pd.to_datetime(transactions['date'])
    transaction_metrics['date'] = pd.to_datetime(transaction_metrics['date'])
    customer_metrics['last_purchase_date'] = pd.to_datetime(customer_metrics['last_purchase_date'])
    
    return transactions, customer_metrics, product_metrics, transaction_metrics


def render_sidebar_filters(transactions):
    """Renderiza los filtros en el sidebar."""
    st.sidebar.header("üîç Filtros")
    
    # Filtro de fecha
    min_date = transactions['date'].min().date()
    max_date = transactions['date'].max().date()
    
    date_range = st.sidebar.date_input(
        "Rango de Fechas",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )
    
    # Filtro de tienda
    stores = ['Todas'] + sorted(transactions['store_id'].unique().tolist())
    selected_store = st.sidebar.selectbox("Tienda", stores)
    
    # Filtro de categor√≠a
    categories = ['Todas'] + sorted(transactions['category_name'].dropna().unique().tolist())
    selected_category = st.sidebar.selectbox("Categor√≠a", categories)
    
    return date_range, selected_store, selected_category


def apply_filters(df, date_range, store, category):
    """Aplica los filtros al DataFrame."""
    filtered = df.copy()
    
    # Filtro de fecha
    if len(date_range) == 2:
        start_date, end_date = date_range
        filtered = filtered[
            (filtered['date'].dt.date >= start_date) & 
            (filtered['date'].dt.date <= end_date)
        ]
    
    # Filtro de tienda
    if store != 'Todas':
        filtered = filtered[filtered['store_id'] == int(store)]
    
    # Filtro de categor√≠a
    if category != 'Todas':
        filtered = filtered[filtered['category_name'] == category]
    
    return filtered


def render_dashboard(transactions, customer_metrics, product_metrics):
    """Renderiza el Dashboard Ejecutivo."""
    st.header("üìä Dashboard Ejecutivo")
    st.markdown("---")
    
    # Calcular m√©tricas
    calc = MetricsCalculator()
    kpis = calc.calculate_kpis(transactions)
    
    # Mostrar KPIs principales en 4 columnas
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="üì¶ Total Unidades",
            value=f"{kpis['total_units']:,}",
            delta=None
        )
    
    with col2:
        st.metric(
            label="üõí Transacciones",
            value=f"{kpis['total_transactions']:,}",
            delta=None
        )
    
    with col3:
        st.metric(
            label="üë• Clientes √önicos",
            value=f"{kpis['total_customers']:,}",
            delta=None
        )
    
    with col4:
        st.metric(
            label="üè∑Ô∏è Productos √önicos",
            value=f"{kpis['total_products']:,}",
            delta=None
        )
    
    st.markdown("---")
    
    # M√©tricas adicionales
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            label="üìà Avg. Productos/Canasta",
            value=f"{kpis['avg_basket_size']:.2f}"
        )
    
    with col2:
        st.metric(
            label="üìä Avg. Unidades/Transacci√≥n",
            value=f"{kpis['avg_units_per_transaction']:.2f}"
        )
    
    with col3:
        days = kpis['date_range']['days']
        st.metric(
            label="üìÖ D√≠as Analizados",
            value=f"{days}"
        )
    
    st.markdown("---")
    
    # Visualizaciones en 2 columnas
    viz = Visualizer()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üèÜ Top 10 Productos")
        fig = viz.plot_top_products(product_metrics, n=10)
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        st.subheader("üë§ Top 10 Clientes")
        fig = viz.plot_top_customers(customer_metrics, n=10)
        st.plotly_chart(fig, width='stretch')
    
    st.markdown("---")
    
    # Segunda fila de visualizaciones
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Top 10 Categor√≠as")
        category_perf = calc.calculate_category_performance(transactions)
        fig = viz.plot_category_distribution(category_perf, n=10, chart_type='bar')
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        st.subheader("üìÖ Transacciones por D√≠a de Semana")
        fig = viz.plot_heatmap_day_hour(transactions)
        st.plotly_chart(fig, width='stretch')
    
    st.markdown("---")
    
    # Serie temporal completa
    st.subheader("üìà Evoluci√≥n Temporal de Ventas")
    
    freq_option = st.radio(
        "Frecuencia",
        options=['Diaria', 'Semanal', 'Mensual'],
        horizontal=True
    )
    
    freq_map = {'Diaria': 'D', 'Semanal': 'W', 'Mensual': 'M'}
    fig = viz.plot_time_series(transactions, freq=freq_map[freq_option], metric='quantity')
    st.plotly_chart(fig, width='stretch')


def render_temporal_analysis(transactions):
    """Renderiza el an√°lisis temporal."""
    st.header("‚è∞ An√°lisis Temporal")
    st.markdown("---")
    
    calc = MetricsCalculator()
    viz = Visualizer()
    
    # Serie temporal con diferentes m√©tricas
    st.subheader("üìà Evoluci√≥n de M√©tricas")
    
    col1, col2 = st.columns(2)
    with col1:
        metric = st.selectbox(
            "M√©trica",
            options=['Unidades Vendidas', 'Transacciones', 'Clientes √önicos']
        )
    with col2:
        freq = st.selectbox(
            "Frecuencia",
            options=['Diaria', 'Semanal', 'Mensual']
        )
    
    metric_map = {
        'Unidades Vendidas': 'quantity',
        'Transacciones': 'transactions',
        'Clientes √önicos': 'customers'
    }
    freq_map = {'Diaria': 'D', 'Semanal': 'W', 'Mensual': 'M'}
    
    fig = viz.plot_time_series(
        transactions,
        freq=freq_map[freq],
        metric=metric_map[metric]
    )
    st.plotly_chart(fig, width='stretch')
    
    st.markdown("---")
    
    # Patrones temporales
    st.subheader("üìä Patrones Temporales")
    
    patterns = calc.calculate_temporal_patterns(transactions)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Por D√≠a de Semana**")
        fig = viz.plot_heatmap_day_hour(transactions)
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        st.write("**Por Mes**")
        month_data = patterns['by_month'].copy()
        month_names = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun', 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']
        month_data['month_name'] = month_data['month'].apply(lambda x: month_names[int(x)-1])
        
        fig = px.bar(
            month_data,
            x='month_name',
            y='quantity',
            title='Ventas por Mes',
            labels={'quantity': 'Unidades', 'month_name': 'Mes'}
        )
        st.plotly_chart(fig, width='stretch')


def render_distributions_analysis(customer_metrics, product_metrics):
    """Renderiza el an√°lisis de distribuciones."""
    st.header("üìä An√°lisis de Distribuciones")
    st.markdown("---")
    
    viz = Visualizer()
    
    # An√°lisis de clientes
    st.subheader("üë• Distribuciones por Cliente")
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = viz.plot_boxplot(
            customer_metrics,
            column='frequency',
            title='Distribuci√≥n de Frecuencia de Compra'
        )
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        fig = viz.plot_histogram(
            customer_metrics,
            column='total_quantity',
            bins=50,
            title='Distribuci√≥n de Cantidad Total por Cliente'
        )
        st.plotly_chart(fig, width='stretch')
    
    st.markdown("---")
    
    # An√°lisis de productos
    st.subheader("üè∑Ô∏è Distribuciones por Producto")
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = viz.plot_boxplot(
            product_metrics,
            column='total_quantity',
            title='Distribuci√≥n de Ventas por Producto'
        )
        st.plotly_chart(fig, width='stretch')
    
    with col2:
        fig = viz.plot_histogram(
            product_metrics,
            column='unique_customers',
            bins=30,
            title='Distribuci√≥n de Alcance por Producto'
        )
        st.plotly_chart(fig, width='stretch')


def render_correlations_analysis(customer_metrics):
    """Renderiza el an√°lisis de correlaciones."""
    st.header("üîó An√°lisis de Correlaciones")
    st.markdown("---")
    
    viz = Visualizer()
    
    # Matriz de correlaci√≥n
    st.subheader("üìä Matriz de Correlaci√≥n")
    
    fig = viz.plot_correlation_heatmap(customer_metrics)
    st.plotly_chart(fig, width='stretch')
    
    st.markdown("---")
    
    # Scatter plots
    st.subheader("üìà Relaciones entre Variables")
    
    col1, col2 = st.columns(2)
    
    with col1:
        x_var = st.selectbox(
            "Variable X",
            options=['frequency', 'recency', 'total_quantity', 'unique_products']
        )
    
    with col2:
        y_var = st.selectbox(
            "Variable Y",
            options=['total_quantity', 'unique_products', 'frequency', 'recency']
        )
    
    fig = viz.plot_scatter_2d(
        customer_metrics,
        x=x_var,
        y=y_var,
        title=f'{y_var} vs {x_var}'
    )
    st.plotly_chart(fig, width='stretch')


@st.cache_data
def prepare_clustering_data(customer_metrics):
    """Prepara datos para clustering (cached - solo se ejecuta una vez)."""
    segmenter = CustomerSegmentation()
    _, x_scaled = segmenter.prepare_features(customer_metrics)
    return x_scaled, segmenter.features_used


@st.cache_data
def calculate_optimal_k(x_scaled, min_k=2, max_k=8):
    """Calcula K √≥ptimo (cached - solo se ejecuta una vez por rango)."""
    segmenter = CustomerSegmentation()
    # Restaurar las features escaladas
    segmenter.scaled_features = x_scaled
    optimization_results = segmenter.find_optimal_k(x_scaled, min_k=min_k, max_k=max_k)
    return optimization_results


@st.cache_data
def train_clustering_model(_x_scaled, n_clusters):
    """Entrena el modelo de clustering (cached por n√∫mero de clusters)."""
    segmenter = CustomerSegmentation()
    segmenter.scaled_features = _x_scaled
    labels = segmenter.fit_kmeans(_x_scaled, n_clusters)
    return labels


def render_customer_segmentation(customer_metrics):
    """Renderiza la p√°gina de segmentaci√≥n de clientes."""
    st.header("üë• Segmentaci√≥n de Clientes")
    st.markdown("---")
    
    st.markdown("""
    La segmentaci√≥n de clientes utiliza **K-Means Clustering** basado en:
    - üìä **Frecuencia**: N√∫mero de transacciones
    - üõçÔ∏è **Productos √∫nicos**: Diversidad de productos comprados
    - üì¶ **Volumen total**: Cantidad total de unidades
    - üè∑Ô∏è **Categor√≠as √∫nicas**: Diversidad de categor√≠as
    """)
    
    st.markdown("---")
    
    # Preparar datos (se ejecuta una sola vez y se cachea)
    x_scaled, features_used = prepare_clustering_data(customer_metrics)
    
    col_info1, col_info2, col_info3 = st.columns([2, 1, 1])
    with col_info1:
        st.success(f"‚úÖ Datos preparados: {len(customer_metrics):,} clientes con {len(features_used)} features")
    with col_info2:
        st.info("üíæ Usando cach√©")
    with col_info3:
        if st.button("üîÑ Limpiar cach√©", help="Limpiar todos los resultados cacheados y recalcular"):
            st.cache_data.clear()
            st.rerun()
    
    # Paso 1: Encontrar K √≥ptimo
    st.subheader("üîç Paso 1: Determinar N√∫mero √ìptimo de Clusters")
    
    with st.expander("Ver an√°lisis de optimizaci√≥n", expanded=False):
        st.info("‚ÑπÔ∏è Este an√°lisis se calcula una sola vez y se mantiene en cach√©. No se recalcular√° al cambiar el n√∫mero de clusters.")
        
        # Esta optimizaci√≥n se cachea y no se vuelve a calcular
        optimization_results = calculate_optimal_k(x_scaled, min_k=ClusteringConfig.MIN_CLUSTERS, max_k=ClusteringConfig.MAX_CLUSTERS)
        
        # Crear visualizaci√≥n (necesitamos un segmenter temporal solo para el plot)
        segmenter_temp = CustomerSegmentation()
        fig = segmenter_temp.plot_elbow_method(optimization_results)
        st.plotly_chart(fig, width='stretch')
        
        st.success(f"üí° **K √≥ptimo recomendado**: {optimization_results['recommended_k']} clusters (basado en Silhouette Score)")
    
    st.markdown("---")
    
    # Paso 2: Seleccionar n√∫mero de clusters
    st.subheader("‚öôÔ∏è Paso 2: Configurar Segmentaci√≥n")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        n_clusters = st.slider(
            "N√∫mero de Clusters",
            min_value=ClusteringConfig.MIN_CLUSTERS,
            max_value=ClusteringConfig.MAX_CLUSTERS,
            value=optimization_results['recommended_k'],
            help="Selecciona el n√∫mero de segmentos de clientes"
        )
    
    with col2:
        viz_type = st.radio(
            "Visualizaci√≥n",
            options=['2D', '3D'],
            horizontal=True
        )
    
    st.markdown("---")
    
    # Paso 3: Entrenar y visualizar
    st.subheader("üìä Paso 3: Resultados de Segmentaci√≥n")
    
    # Entrenar modelo (se cachea por n_clusters, no se recalcula si ya existe)
    labels = train_clustering_model(x_scaled, n_clusters)
    
    # Crear segmenter para funciones de visualizaci√≥n
    segmenter = CustomerSegmentation()
    segmenter.scaled_features = x_scaled
    segmenter.features_used = features_used
    
    # Reducir dimensionalidad para visualizaci√≥n
    n_components = 3 if viz_type == '3D' else 2
    x_reduced = segmenter.reduce_dimensions(x_scaled, n_components=n_components)
    
    # Perfilar clusters
    profile = segmenter.profile_clusters(customer_metrics, labels)
    cluster_names = segmenter.name_clusters(profile)
    
    # Mostrar m√©tricas de calidad
    col_success1, col_success2 = st.columns([3, 1])
    with col_success1:
        st.success(f"‚úÖ Modelo entrenado exitosamente con {n_clusters} clusters")
    with col_success2:
        st.info("üíæ Resultado cacheado")
    
    # Visualizaci√≥n de clusters
    st.markdown("### üé® Visualizaci√≥n de Clusters")
    
    if viz_type == '2D':
        fig = segmenter.plot_clusters_2d(x_reduced, labels, cluster_names)
    else:
        fig = segmenter.plot_clusters_3d(x_reduced, labels, cluster_names)
    
    st.plotly_chart(fig, width='stretch')
    
    st.markdown("---")
    
    # Paso 4: Perfil de clusters
    st.subheader("üìã Paso 4: Perfil de Cada Segmento")
    
    for cluster_id in sorted(profile['cluster'].unique()):
        cluster_data = profile[profile['cluster'] == cluster_id].iloc[0]
        cluster_info = cluster_names[cluster_id]
        
        with st.expander(f"üîµ Cluster {cluster_id}: {cluster_info['name']}", expanded=True):
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Tama√±o", f"{int(cluster_data['size']):,}")
                st.metric("Porcentaje", f"{cluster_data['percentage']:.1f}%")
            
            with col2:
                st.metric("Frecuencia Promedio", f"{cluster_data['avg_frequency']:.1f}")
                st.metric("Productos Promedio", f"{cluster_data['avg_products']:.1f}")
            
            with col3:
                st.metric("Volumen Total", f"{int(cluster_data['total_volume']):,}")
                st.metric("Categor√≠as Promedio", f"{cluster_data['avg_categories']:.1f}")
            
            st.markdown(f"**üìù Descripci√≥n**: {cluster_info['description']}")
            st.markdown(f"**üéØ Estrategia Recomendada**: {cluster_info['strategy']}")
    
    st.markdown("---")
    
    # Paso 5: Tabla comparativa
    st.subheader("üìä Paso 5: Comparaci√≥n de Segmentos")
    
    # Agregar nombres a la tabla
    profile_display = profile.copy()
    profile_display['nombre'] = profile_display['cluster'].map(
        lambda x: cluster_names[x]['name']
    )
    
    # Seleccionar columnas relevantes
    display_cols = [
        'cluster', 'nombre', 'size', 'percentage',
        'avg_frequency', 'avg_quantity', 'avg_products', 'avg_categories'
    ]
    
    st.dataframe(
        profile_display[display_cols].style.format({
            'size': '{:,.0f}',
            'percentage': '{:.1f}%',
            'avg_frequency': '{:.1f}',
            'avg_quantity': '{:.1f}',
            'avg_products': '{:.1f}',
            'avg_categories': '{:.1f}'
        }),
        width='stretch'
    ) 
    st.markdown("---")
    
    # Paso 6: Descargar resultados
    st.subheader("üíæ Paso 6: Exportar Resultados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Agregar labels al dataframe de clientes
        customer_segments = customer_metrics.copy()
        customer_segments['cluster'] = labels
        customer_segments['cluster_name'] = customer_segments['cluster'].map(
            lambda x: cluster_names[x]['name']
        )
        
        csv = customer_segments.to_csv(index=False)
        st.download_button(
            label="üì• Descargar Clientes Segmentados (CSV)",
            data=csv,
            file_name="customer_segments.csv",
            mime="text/csv"
        )
    
    with col2:
        csv_profile = profile_display.to_csv(index=False)
        st.download_button(
            label="üì• Descargar Perfil de Segmentos (CSV)",
            data=csv_profile,
            file_name="cluster_profiles.csv",
            mime="text/csv"
        )


def render_data_upload():
    """Renderiza la p√°gina de Carga de Nuevos Datos."""
    st.header("üì§ Carga de Nuevos Datos")
    
    st.markdown("""
    Esta funcionalidad permite cargar nuevos archivos de transacciones para actualizar el an√°lisis.
    Los datos se validar√°n autom√°ticamente antes de ser procesados.
    """)
    
    st.markdown("---")
    
    # Informaci√≥n sobre el formato esperado
    with st.expander("‚ÑπÔ∏è Formato de Datos Esperado", expanded=False):
        st.markdown("""
        **Archivos soportados:**
        
        1. **Archivos de Transacciones** (formato: `XXX_Tran.csv`)
           - Columnas requeridas: `date`, `store_id`, `customer_id`, `products`
           - Formato de fecha: `YYYY-MM-DD` (ejemplo: 2013-01-01)
           - Formato de productos: IDs separados por espacios (ejemplo: "20 3 1 5")
           - El nombre del archivo debe indicar el ID de tienda (ejemplo: 102_Tran.csv)
        
        2. **Categories.csv** (opcional - para actualizar categor√≠as)
           - Columnas: `category_id`, `category_name`
        
        3. **ProductCategory.csv** (opcional - para actualizar relaciones)
           - Columnas: `product_id`, `category_id`
        
        **Nota:** Los archivos se validar√°n antes de procesarse.
        """)
    
    st.markdown("---")
    
    # Tabs para diferentes tipos de carga
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä Cargar Transacciones", 
        "üè∑Ô∏è Cargar Categor√≠as",
        "üîó Cargar Producto-Categor√≠a",
        "üìà Ver Estado Actual"
    ])
    
    with tab1:
        st.subheader("Cargar Nuevo Archivo de Transacciones")
        
        # File uploader
        uploaded_file = st.file_uploader(
            "Selecciona un archivo CSV",
            type=['csv'],
            help="Archivo de transacciones en formato XXX_Tran.csv"
        )
        
        if uploaded_file is not None:
            # Mostrar informaci√≥n del archivo
            st.info(f"üìÅ Archivo: **{uploaded_file.name}** ({uploaded_file.size / 1024:.2f} KB)")
            
            try:
                # Leer el archivo
                import io
                file_content = uploaded_file.getvalue().decode('utf-8')
                
                # Detectar delimitador
                delimiter = ','
                if '|' in file_content.split('\n')[0]:
                    delimiter = '|'
                
                # Intentar leer con encabezados primero
                uploaded_df = pd.read_csv(io.StringIO(file_content), sep=delimiter)
                
                # Validar estructura
                st.markdown("### ‚úÖ Paso 1: Validaci√≥n de Estructura")
                
                required_columns = ['date', 'store_id', 'customer_id', 'products']
                
                # Detectar si el archivo no tiene encabezados (columnas num√©ricas 0, 1, 2, 3)
                # o si tiene columnas pero no coinciden con las esperadas
                if (uploaded_df.columns.tolist() == [0, 1, 2, 3] or 
                    all(str(col).isdigit() for col in uploaded_df.columns) or
                    not any(col in uploaded_df.columns for col in required_columns)):
                    
                    st.warning("‚ö†Ô∏è Archivo sin encabezados detectado. Asignando nombres de columnas...")
                    
                    # Verificar que tenga exactamente 4 columnas
                    if len(uploaded_df.columns) != 4:
                        st.error(f"‚ùå El archivo debe tener exactamente 4 columnas, pero tiene {len(uploaded_df.columns)}")
                        st.info("Formato esperado: date, store_id, customer_id, products")
                        st.stop()
                    
                    # Asignar nombres de columnas correctos
                    uploaded_df.columns = required_columns
                    st.success(f"‚úÖ Nombres asignados autom√°ticamente. Delimitador detectado: '{delimiter}'")
                else:
                    # Verificar columnas faltantes
                    missing_columns = [col for col in required_columns if col not in uploaded_df.columns]
                    
                    if missing_columns:
                        st.error(f"‚ùå Columnas faltantes: {', '.join(missing_columns)}")
                        st.info(f"üìã Columnas encontradas: {', '.join(uploaded_df.columns.tolist())}")
                        st.info(f"üìã Columnas requeridas: {', '.join(required_columns)}")
                        st.stop()
                    else:
                        st.success("‚úÖ Todas las columnas requeridas est√°n presentes")
                
                # Mostrar preview
                st.markdown("### üìã Paso 2: Preview de Datos")
                st.dataframe(uploaded_df.head(10), width='stretch')
                
                # Mostrar estad√≠sticas b√°sicas
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Filas", f"{len(uploaded_df):,}")
                with col2:
                    st.metric("Clientes √önicos", f"{uploaded_df['customer_id'].nunique():,}")
                with col3:
                    st.metric("Tiendas", f"{uploaded_df['store_id'].nunique()}")
                with col4:
                    # Contar productos √∫nicos
                    all_products = set()
                    for products_str in uploaded_df['products'].dropna():
                        all_products.update(products_str.split())
                    st.metric("Productos √önicos", f"{len(all_products):,}")
                
                st.markdown("---")
                
                # Validaciones adicionales
                st.markdown("### üîç Paso 3: Validaciones Adicionales")
                
                validations = []
                
                # Validar fechas
                try:
                    pd.to_datetime(uploaded_df['date'])
                    validations.append(("Formato de fechas", True, "Fechas v√°lidas"))
                except:
                    validations.append(("Formato de fechas", False, "Error en formato de fechas"))
                
                # Validar valores nulos
                null_counts = uploaded_df[required_columns].isnull().sum()
                has_nulls = null_counts.sum() > 0
                validations.append((
                    "Valores nulos",
                    not has_nulls,
                    "Sin valores nulos" if not has_nulls else f"Encontrados valores nulos: {null_counts[null_counts > 0].to_dict()}"
                ))
                
                # Validar IDs positivos
                positive_ids = (uploaded_df['customer_id'] > 0).all() and (uploaded_df['store_id'] > 0).all()
                validations.append((
                    "IDs v√°lidos",
                    positive_ids,
                    "Todos los IDs son positivos" if positive_ids else "Algunos IDs son negativos o cero"
                ))
                
                # Mostrar resultados de validaci√≥n
                for validation_name, is_valid, message in validations:
                    if is_valid:
                        st.success(f"‚úÖ **{validation_name}**: {message}")
                    else:
                        st.error(f"‚ùå **{validation_name}**: {message}")
                
                all_valid = all(v[1] for v in validations)
                
                st.markdown("---")
                
                # Opciones de procesamiento
                st.markdown("### ‚öôÔ∏è Paso 4: Opciones de Procesamiento")
                
                col1, col2 = st.columns(2)
                with col1:
                    process_mode = st.radio(
                        "Modo de procesamiento:",
                        ["Agregar a datos existentes", "Reemplazar datos existentes"],
                        help="Agregar: a√±ade a los datos actuales. Reemplazar: sobrescribe completamente."
                    )
                
                with col2:
                    recalculate_all = st.checkbox(
                        "Recalcular todas las m√©tricas",
                        value=True,
                        help="Recalcula customer_metrics, product_metrics, etc."
                    )
                
                st.markdown("---")
                
                # Bot√≥n de procesamiento
                if all_valid:
                    if st.button("üöÄ Procesar y Actualizar Datos", type="primary", use_container_width=True):
                        with st.spinner("Procesando datos..."):
                            try:
                                # Crear progress bar
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                # Paso 1: Cargar datos existentes
                                status_text.text("Cargando datos existentes...")
                                progress_bar.progress(10)
                                
                                loader = DataLoader()
                                processor = DataProcessor()
                                
                                # Paso 2: Procesar nuevo archivo
                                status_text.text("Procesando nuevo archivo...")
                                progress_bar.progress(30)
                                
                                # Expandir transacciones del nuevo archivo
                                status_text.text("Expandiendo transacciones...")
                                new_transactions = processor.expand_transactions(uploaded_df)
                                
                                progress_bar.progress(40)
                                
                                # Enriquecer con categor√≠as
                                status_text.text("Enriqueciendo con categor√≠as...")
                                product_category = loader.load_product_category()
                                categories = loader.load_categories()
                                new_transactions = processor.enrich_with_categories(
                                    new_transactions, 
                                    product_category, 
                                    categories
                                )
                                
                                progress_bar.progress(55)
                                
                                # Agregar features temporales
                                status_text.text("Agregando features temporales...")
                                new_transactions = processor.add_temporal_features(new_transactions)
                                
                                progress_bar.progress(70)
                                
                                # Combinar con datos existentes si es modo agregar
                                if process_mode == "Agregar a datos existentes":
                                    status_text.text("Combinando con datos existentes...")
                                    existing_transactions = pd.read_csv(Paths.DATA_PROCESSED / 'transactions_expanded.csv')
                                    combined_transactions = pd.concat([existing_transactions, new_transactions], ignore_index=True)
                                else:
                                    combined_transactions = new_transactions
                                
                                progress_bar.progress(80)
                                
                                # Guardar datos actualizados
                                status_text.text("Guardando datos actualizados...")
                                combined_transactions.to_csv(Paths.DATA_PROCESSED / 'transactions_expanded.csv', index=False)
                                
                                progress_bar.progress(90)
                                
                                # Recalcular m√©tricas si se solicita
                                if recalculate_all:
                                    status_text.text("Recalculando m√©tricas...")
                                    
                                    customer_metrics = processor.calculate_customer_metrics(combined_transactions)
                                    customer_metrics.to_csv(Paths.DATA_PROCESSED / 'customer_metrics.csv', index=False)
                                    
                                    product_metrics = processor.calculate_product_metrics(combined_transactions)
                                    product_metrics.to_csv(Paths.DATA_PROCESSED / 'product_metrics.csv', index=False)
                                    
                                    transaction_metrics = processor.calculate_transaction_metrics(combined_transactions)
                                    transaction_metrics.to_csv(Paths.DATA_PROCESSED / 'transaction_metrics.csv', index=False)
                                
                                progress_bar.progress(100)
                                status_text.text("‚úÖ Procesamiento completado!")
                                
                                # Limpiar cach√©
                                st.cache_data.clear()
                                
                                # Mostrar comparaci√≥n antes/despu√©s
                                st.markdown("---")
                                st.markdown("### üìä Resumen de Actualizaci√≥n")
                                
                                # Calcular deltas
                                if process_mode == "Agregar a datos existentes":
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        new_rows = len(new_transactions)
                                        st.metric(
                                            "Transacciones Agregadas",
                                            f"{new_rows:,}",
                                            delta=f"+{new_rows:,}"
                                        )
                                    
                                    with col2:
                                        new_customers = new_transactions['customer_id'].nunique()
                                        st.metric(
                                            "Nuevos Clientes",
                                            f"{new_customers:,}",
                                            delta=f"+{new_customers:,}"
                                        )
                                    
                                    with col3:
                                        new_products = new_transactions['product_id'].nunique()
                                        st.metric(
                                            "Nuevos Productos",
                                            f"{new_products:,}",
                                            delta=f"+{new_products:,}"
                                        )
                                
                                st.success("‚úÖ Datos actualizados exitosamente. Recarga la p√°gina para ver los cambios.")
                                
                                # Bot√≥n para recargar
                                if st.button("üîÑ Recargar Aplicaci√≥n"):
                                    st.rerun()
                                
                            except Exception as e:
                                st.error(f"‚ùå Error al procesar datos: {str(e)}")
                                logger.error(f"Error en carga de datos: {e}", exc_info=True)
                else:
                    st.warning("‚ö†Ô∏è Por favor corrige los errores de validaci√≥n antes de procesar.")
                    
            except Exception as e:
                st.error(f"‚ùå Error al leer el archivo: {str(e)}")
                logger.error(f"Error en lectura de archivo: {e}", exc_info=True)
    
    with tab2:
        st.subheader("Cargar Archivo de Categor√≠as")
        
        st.markdown("""
        Sube un archivo `Categories.csv` para actualizar el cat√°logo de categor√≠as.
        
        **Formato esperado:**
        - `category_id`: ID num√©rico de la categor√≠a
        - `category_name`: Nombre descriptivo de la categor√≠a
        """)
        
        categories_file = st.file_uploader(
            "Selecciona archivo Categories.csv",
            type=['csv'],
            key='categories_uploader',
            help="Archivo con categor√≠as de productos"
        )
        
        if categories_file is not None:
            st.info(f"üìÅ Archivo: **{categories_file.name}** ({categories_file.size / 1024:.2f} KB)")
            
            try:
                import io
                file_content = categories_file.getvalue().decode('utf-8')
                
                # Intentar detectar delimitador
                delimiter = ','
                if '|' in file_content.split('\n')[0]:
                    delimiter = '|'
                
                # Intentar leer con encabezados primero
                categories_df = pd.read_csv(io.StringIO(file_content), sep=delimiter)
                
                st.markdown("### ‚úÖ Validaci√≥n de Estructura")
                
                required_columns = ['category_id', 'category_name']
                
                # Detectar si no tiene encabezados
                if (categories_df.columns.tolist() == [0, 1] or 
                    all(str(col).isdigit() for col in categories_df.columns) or
                    not any(col in categories_df.columns for col in required_columns)):
                    
                    st.warning("‚ö†Ô∏è Archivo sin encabezados detectado. Asignando nombres de columnas...")
                    
                    # Verificar que tenga exactamente 2 columnas
                    if len(categories_df.columns) != 2:
                        st.error(f"‚ùå El archivo debe tener exactamente 2 columnas, pero tiene {len(categories_df.columns)}")
                        st.info("Formato esperado: category_id, category_name")
                        st.stop()
                    
                    # Asignar nombres de columnas correctos
                    categories_df.columns = required_columns
                    st.success(f"‚úÖ Nombres asignados autom√°ticamente. Delimitador detectado: '{delimiter}'")
                else:
                    # Verificar columnas faltantes
                    missing_columns = [col for col in required_columns if col not in categories_df.columns]
                    
                    if missing_columns:
                        st.error(f"‚ùå Columnas faltantes: {', '.join(missing_columns)}")
                        st.info(f"üìã Columnas requeridas: {', '.join(required_columns)}")
                        st.stop()
                
                st.success("‚úÖ Estructura v√°lida")
                
                # Preview
                st.markdown("### üìã Preview de Datos")
                st.dataframe(categories_df.head(20), width='stretch')
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Total Categor√≠as", f"{len(categories_df):,}")
                with col2:
                    st.metric("Categor√≠as √önicas", f"{categories_df['category_id'].nunique():,}")
                
                # Validaciones
                st.markdown("### ‚úÖ Validaciones")
                validation_passed = True
                
                # 1. IDs duplicados
                duplicates = categories_df['category_id'].duplicated().sum()
                if duplicates > 0:
                    st.error(f"‚ùå Se encontraron {duplicates} IDs de categor√≠a duplicados")
                    validation_passed = False
                else:
                    st.success("‚úÖ No hay IDs duplicados")
                
                # 2. Valores nulos
                nulls = categories_df.isnull().sum().sum()
                if nulls > 0:
                    st.error(f"‚ùå Se encontraron {nulls} valores nulos")
                    validation_passed = False
                else:
                    st.success("‚úÖ No hay valores nulos")
                
                # 3. IDs positivos
                if (categories_df['category_id'] <= 0).any():
                    st.error("‚ùå Algunos category_id no son positivos")
                    validation_passed = False
                else:
                    st.success("‚úÖ Todos los IDs son positivos")
                
                if validation_passed:
                    st.markdown("---")
                    
                    # Modo de actualizaci√≥n
                    update_mode = st.radio(
                        "Modo de actualizaci√≥n",
                        ["Agregar nuevas categor√≠as", "Reemplazar todas las categor√≠as"],
                        help="Agregar: combina con categor√≠as existentes. Reemplazar: elimina las actuales."
                    )
                    
                    if st.button("üöÄ Procesar Categor√≠as", type="primary"):
                        with st.spinner("Procesando..."):
                            try:
                                if update_mode == "Agregar nuevas categor√≠as":
                                    # Cargar categor√≠as existentes
                                    existing_categories = pd.read_csv(Paths.DATA_RAW / 'Categories.csv')
                                    
                                    # Combinar (las nuevas sobrescriben las existentes con mismo ID)
                                    combined_categories = pd.concat([existing_categories, categories_df])
                                    combined_categories = combined_categories.drop_duplicates(
                                        subset=['category_id'], 
                                        keep='last'
                                    ).sort_values('category_id')
                                else:
                                    combined_categories = categories_df.sort_values('category_id')
                                
                                # Guardar
                                combined_categories.to_csv(Paths.DATA_RAW / 'Categories.csv', index=False)
                                
                                st.success("‚úÖ Categor√≠as actualizadas exitosamente!")
                                st.info(f"üìä Total de categor√≠as: {len(combined_categories):,}")
                                
                                # Mostrar cambios
                                if update_mode == "Agregar nuevas categor√≠as":
                                    new_count = len(combined_categories) - len(existing_categories)
                                    if new_count > 0:
                                        st.success(f"‚ûï {new_count} nuevas categor√≠as agregadas")
                                    updated_count = len(categories_df) - new_count
                                    if updated_count > 0:
                                        st.info(f"üîÑ {updated_count} categor√≠as actualizadas")
                                
                                st.warning("‚ö†Ô∏è **Importante:** Debes reprocesar las transacciones para que los cambios se reflejen en el sistema.")
                                
                                if st.button("üîÑ Recargar Aplicaci√≥n"):
                                    st.rerun()
                                
                            except Exception as e:
                                st.error(f"‚ùå Error al procesar: {str(e)}")
                                logger.error(f"Error en carga de categor√≠as: {e}", exc_info=True)
                else:
                    st.warning("‚ö†Ô∏è Por favor corrige los errores de validaci√≥n.")
                    
            except Exception as e:
                st.error(f"‚ùå Error al leer el archivo: {str(e)}")
                logger.error(f"Error en lectura de categor√≠as: {e}", exc_info=True)
    
    with tab3:
        st.subheader("Cargar Archivo de Producto-Categor√≠a")
        
        st.markdown("""
        Sube un archivo `ProductCategory.csv` para actualizar las relaciones producto-categor√≠a.
        
        **Formato esperado:**
        - `product_id`: ID num√©rico del producto
        - `category_id`: ID num√©rico de la categor√≠a
        """)
        
        product_category_file = st.file_uploader(
            "Selecciona archivo ProductCategory.csv",
            type=['csv'],
            key='product_category_uploader',
            help="Archivo con relaciones producto-categor√≠a"
        )
        
        if product_category_file is not None:
            st.info(f"üìÅ Archivo: **{product_category_file.name}** ({product_category_file.size / 1024:.2f} KB)")
            
            try:
                import io
                file_content = product_category_file.getvalue().decode('utf-8')
                
                # Intentar detectar delimitador
                delimiter = ','
                if '|' in file_content.split('\n')[0]:
                    delimiter = '|'
                
                # Intentar leer con encabezados primero
                product_category_df = pd.read_csv(io.StringIO(file_content), sep=delimiter)
                
                st.markdown("### ‚úÖ Validaci√≥n de Estructura")
                
                required_columns = ['product_id', 'category_id']
                
                # Detectar si no tiene encabezados
                if (product_category_df.columns.tolist() == [0, 1] or 
                    all(str(col).isdigit() for col in product_category_df.columns) or
                    not any(col in product_category_df.columns for col in required_columns)):
                    
                    st.warning("‚ö†Ô∏è Archivo sin encabezados detectado. Asignando nombres de columnas...")
                    
                    # Verificar que tenga exactamente 2 columnas
                    if len(product_category_df.columns) != 2:
                        st.error(f"‚ùå El archivo debe tener exactamente 2 columnas, pero tiene {len(product_category_df.columns)}")
                        st.info("Formato esperado: product_id, category_id")
                        st.stop()
                    
                    # Asignar nombres de columnas correctos
                    product_category_df.columns = required_columns
                    st.success(f"‚úÖ Nombres asignados autom√°ticamente. Delimitador detectado: '{delimiter}'")
                else:
                    # Verificar columnas faltantes
                    missing_columns = [col for col in required_columns if col not in product_category_df.columns]
                    
                    if missing_columns:
                        st.error(f"‚ùå Columnas faltantes: {', '.join(missing_columns)}")
                        st.info(f"üìã Columnas requeridas: {', '.join(required_columns)}")
                        st.stop()
                
                st.success("‚úÖ Estructura v√°lida")
                
                # Preview
                st.markdown("### üìã Preview de Datos")
                st.dataframe(product_category_df.head(20), width='stretch')
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Total Relaciones", f"{len(product_category_df):,}")
                with col2:
                    st.metric("Productos √önicos", f"{product_category_df['product_id'].nunique():,}")
                
                # Validaciones
                st.markdown("### ‚úÖ Validaciones")
                validation_passed = True
                
                # 1. IDs duplicados
                duplicates = product_category_df['product_id'].duplicated().sum()
                if duplicates > 0:
                    st.warning(f"‚ö†Ô∏è Se encontraron {duplicates} product_id duplicados (se mantendr√° la √∫ltima asignaci√≥n)")
                
                # 2. Valores nulos
                nulls = product_category_df.isnull().sum().sum()
                if nulls > 0:
                    st.error(f"‚ùå Se encontraron {nulls} valores nulos")
                    validation_passed = False
                else:
                    st.success("‚úÖ No hay valores nulos")
                
                # 3. IDs positivos
                if (product_category_df['product_id'] <= 0).any() or (product_category_df['category_id'] <= 0).any():
                    st.error("‚ùå Algunos IDs no son positivos")
                    validation_passed = False
                else:
                    st.success("‚úÖ Todos los IDs son positivos")
                
                # 4. Verificar categor√≠as existentes
                try:
                    # Leer categor√≠as existentes (formato con pipe y sin encabezados)
                    existing_categories = pd.read_csv(
                        Paths.DATA_RAW / 'Categories.csv', 
                        sep='|', 
                        header=None, 
                        names=['category_id', 'category_name']
                    )
                    
                    unknown_categories = set(product_category_df['category_id']) - set(existing_categories['category_id'])
                    if unknown_categories:
                        st.warning(f"‚ö†Ô∏è {len(unknown_categories)} categor√≠as no existen en Categories.csv: {sorted(list(unknown_categories)[:10])}")
                        st.info("üí° Considera subir primero el archivo de categor√≠as actualizado")
                    else:
                        st.success("‚úÖ Todas las categor√≠as existen")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è No se pudo verificar categor√≠as: {str(e)}")
                
                if validation_passed:
                    st.markdown("---")
                    
                    # Modo de actualizaci√≥n
                    update_mode = st.radio(
                        "Modo de actualizaci√≥n",
                        ["Agregar/Actualizar productos", "Reemplazar todas las relaciones"],
                        help="Agregar: combina con productos existentes. Reemplazar: elimina las actuales."
                    )
                    
                    if st.button("üöÄ Procesar Producto-Categor√≠a", type="primary"):
                        with st.spinner("Procesando..."):
                            try:
                                if update_mode == "Agregar/Actualizar productos":
                                    # Cargar relaciones existentes
                                    existing_pc = pd.read_csv(Paths.DATA_RAW / 'ProductCategory.csv')
                                    
                                    # Combinar (las nuevas sobrescriben las existentes con mismo product_id)
                                    combined_pc = pd.concat([existing_pc, product_category_df])
                                    combined_pc = combined_pc.drop_duplicates(
                                        subset=['product_id'], 
                                        keep='last'
                                    ).sort_values('product_id')
                                else:
                                    combined_pc = product_category_df.sort_values('product_id')
                                
                                # Guardar
                                combined_pc.to_csv(Paths.DATA_RAW / 'ProductCategory.csv', index=False)
                                
                                st.success("‚úÖ Relaciones producto-categor√≠a actualizadas exitosamente!")
                                st.info(f"üìä Total de productos: {len(combined_pc):,}")
                                
                                # Mostrar cambios
                                if update_mode == "Agregar/Actualizar productos":
                                    new_count = len(combined_pc) - len(existing_pc)
                                    if new_count > 0:
                                        st.success(f"‚ûï {new_count} nuevos productos agregados")
                                    updated_count = len(product_category_df) - new_count
                                    if updated_count > 0:
                                        st.info(f"üîÑ {updated_count} productos actualizados")
                                
                                st.warning("‚ö†Ô∏è **Importante:** Debes reprocesar las transacciones para que los cambios se reflejen en el sistema.")
                                
                                if st.button("üîÑ Recargar Aplicaci√≥n"):
                                    st.rerun()
                                
                            except Exception as e:
                                st.error(f"‚ùå Error al procesar: {str(e)}")
                                logger.error(f"Error en carga de producto-categor√≠a: {e}", exc_info=True)
                else:
                    st.warning("‚ö†Ô∏è Por favor corrige los errores de validaci√≥n.")
                    
            except Exception as e:
                st.error(f"‚ùå Error al leer el archivo: {str(e)}")
                logger.error(f"Error en lectura de producto-categor√≠a: {e}", exc_info=True)
    
    with tab4:
        st.subheader("Estado Actual de los Datos")
        
        try:
            # Cargar datos actuales
            transactions_current = pd.read_csv(Paths.DATA_PROCESSED / 'transactions_expanded.csv')
            
            st.markdown("### üìä Resumen de Datos Actuales")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Total Transacciones", f"{len(transactions_current):,}")
            
            with col2:
                st.metric("Clientes √önicos", f"{transactions_current['customer_id'].nunique():,}")
            
            with col3:
                st.metric("Productos √önicos", f"{transactions_current['product_id'].nunique():,}")
            
            with col4:
                st.metric("Tiendas", f"{transactions_current['store_id'].nunique()}")
            
            st.markdown("---")
            
            # Informaci√≥n de fechas
            transactions_current['date'] = pd.to_datetime(transactions_current['date'])
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Fecha M√≠nima", transactions_current['date'].min().strftime('%Y-%m-%d'))
            
            with col2:
                st.metric("Fecha M√°xima", transactions_current['date'].max().strftime('%Y-%m-%d'))
            
            with col3:
                days_span = (transactions_current['date'].max() - transactions_current['date'].min()).days
                st.metric("D√≠as de Datos", f"{days_span:,}")
            
            st.markdown("---")
            
            # Tama√±o de archivos
            st.markdown("### üíæ Almacenamiento")
            
            processed_files = {
                'transactions_expanded.csv': 'Transacciones Expandidas',
                'customer_metrics.csv': 'M√©tricas de Clientes',
                'product_metrics.csv': 'M√©tricas de Productos',
                'transaction_metrics.csv': 'M√©tricas de Transacciones'
            }
            
            file_sizes = []
            for filename, description in processed_files.items():
                file_path = Paths.DATA_PROCESSED / filename
                if file_path.exists():
                    size_mb = file_path.stat().st_size / (1024 * 1024)
                    file_sizes.append({
                        'Archivo': description,
                        'Tama√±o (MB)': f"{size_mb:.2f}"
                    })
            
            if file_sizes:
                st.dataframe(pd.DataFrame(file_sizes), width='stretch', hide_index=True)
            
            st.markdown("---")
            
            # Botones de acci√≥n
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("üóëÔ∏è Limpiar Cach√© de la Aplicaci√≥n", use_container_width=True):
                    st.cache_data.clear()
                    st.success("‚úÖ Cach√© limpiado exitosamente")
            
            with col2:
                if st.button("üîÑ Resetear a Datos Originales", type="primary", use_container_width=True):
                    with st.spinner("‚è≥ Restaurando y procesando datos originales..."):
                        try:
                            # Eliminar archivos procesados
                            processed_dir = Paths.DATA_PROCESSED
                            
                            if processed_dir.exists():
                                shutil.rmtree(processed_dir)
                            processed_dir.mkdir(parents=True)
                            
                            # Ejecutar pipeline de procesamiento
                            loader = DataLoader()
                            processor = DataProcessor()
                            
                            # Cargar datos raw
                            transactions_raw = loader.load_transactions()
                            categories = loader.load_categories()
                            product_category = loader.load_product_category()
                            
                            # Procesar todos los datos usando process_all
                            processed_data = processor.process_all(transactions_raw, product_category, categories)
                            
                            # Guardar datos procesados
                            processed_data['transactions_expanded'].to_csv(Paths.DATA_PROCESSED / 'transactions_expanded.csv', index=False)
                            processed_data['customer_metrics'].to_csv(Paths.DATA_PROCESSED / 'customer_metrics.csv', index=False)
                            processed_data['product_metrics'].to_csv(Paths.DATA_PROCESSED / 'product_metrics.csv', index=False)
                            processed_data['transaction_metrics'].to_csv(Paths.DATA_PROCESSED / 'transaction_metrics.csv', index=False)
                            
                            # Limpiar cach√©
                            st.cache_data.clear()
                            
                            st.success("‚úÖ Datos reseteados y procesados correctamente!")
                            st.info("üí° Recarga la aplicaci√≥n con F5 para ver los cambios")
                            
                        except Exception as e:
                            st.error(f"‚ùå Error al resetear datos: {str(e)}")
                            logger.error(f"Error en reseteo de datos: {e}", exc_info=True)
        
        except FileNotFoundError:
            st.warning("‚ö†Ô∏è No se encontraron datos procesados. Carga algunos datos primero.")


def render_recommendations(transactions):
    """Renderiza la p√°gina de Sistema de Recomendaci√≥n."""
    st.header("üéØ Sistema de Recomendaci√≥n")
    
    # Informaci√≥n sobre cach√©
    with st.expander("‚ÑπÔ∏è Informaci√≥n sobre el Sistema de Cach√©", expanded=False):
        st.markdown("""
        **üöÄ Optimizaci√≥n de Rendimiento:**
        
        Este sistema utiliza cach√© inteligente para acelerar las recomendaciones:
        
        - **üîó Reglas de Asociaci√≥n**: Se cachean seg√∫n los par√°metros de configuraci√≥n (TTL: 1 hora)  
        - **üéØ Recomendaciones por Cliente**: Se cachean por cliente y par√°metros (TTL: 30 minutos)
        - **üéØ Recomendaciones por Producto**: Se cachean por producto y par√°metros (TTL: 30 minutos)
        
        **Beneficios:**
        - ‚ö° Primera consulta: 2-5 minutos (dependiendo de par√°metros)
        - ‚ö° Consultas subsecuentes: < 1 segundo
        - üíæ Limpieza autom√°tica del cach√© despu√©s del tiempo de vida (TTL)
        
        **Nota:** Si cambias los par√°metros de configuraci√≥n, se regenerar√° el cach√© correspondiente.
        """)
        
        if st.button("üóëÔ∏è Limpiar Cach√© del Sistema de Recomendaciones"):
            # Limpiar funciones espec√≠ficas del cach√©
            build_cached_association_rules.clear()
            get_cached_customer_recommendations.clear()
            get_cached_product_recommendations.clear()
            st.success("‚úÖ Cach√© limpiado exitosamente. Las pr√≥ximas consultas recalcular√°n los datos.")
            st.rerun()
    
    st.markdown("---")
    
    # Selector de tipo de recomendaci√≥n
    st.subheader("Selecciona el tipo de recomendaci√≥n")
    
    col1, col2 = st.columns(2)
    
    with col1:
        rec_type = st.radio(
            "Tipo de Recomendaci√≥n",
            options=["Por Cliente", "Por Producto"],
            horizontal=True
        )
    
    st.markdown("---")
    
    # Inicializar recomendador
    recommender = RecommenderSystem()
    
    if rec_type == "Por Cliente":
        st.subheader("üõçÔ∏è Recomendaciones Basadas en Cliente")
        st.info(
            "üí° Este sistema utiliza **Filtrado Colaborativo** para recomendar productos. "
            "Analiza clientes con patrones de compra similares y sugiere productos que ellos han comprado."
        )
        
        # Input de cliente
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            customer_id = st.number_input(
                "ID del Cliente",
                min_value=1,
                value=1000,
                help="Ingresa el ID del cliente para obtener recomendaciones"
            )
        
        with col2:
            top_n = st.number_input(
                "Top N",
                min_value=1,
                max_value=50,
                value=RecommenderConfig.TOP_N,
                help="N√∫mero de productos a recomendar"
            )
        
        with col3:
            min_similarity = st.slider(
                "Similaridad M√≠nima",
                min_value=0.0,
                max_value=1.0,
                value=0.1,
                step=0.05,
                help="Umbral de similaridad entre clientes"
            )
        
        # Bot√≥n para generar recomendaciones
        if st.button("üîç Generar Recomendaciones", type="primary", key="rec_customer"):
            with st.spinner("Analizando clientes similares y generando recomendaciones..."):
                # Obtener estad√≠sticas del cliente
                customer_stats = recommender.get_customer_statistics(customer_id, transactions)
                
                if not customer_stats:
                    st.error(f"‚ùå Cliente {customer_id} no encontrado en los datos.")
                else:
                    # Mostrar informaci√≥n del cliente
                    st.markdown("### üìä Perfil del Cliente")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Transacciones", f"{customer_stats['total_transactions']:,}")
                    with col2:
                        st.metric("Productos √önicos", f"{customer_stats['unique_products']:,}")
                    with col3:
                        st.metric("Unidades Totales", f"{customer_stats['total_quantity']:,}")
                    with col4:
                        st.metric("Categor√≠as", f"{customer_stats['unique_categories']}")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.info(f"**Categor√≠a Favorita:** {customer_stats['favorite_category']}")
                    with col2:
                        st.info(f"**Productos por Transacci√≥n:** {customer_stats['avg_products_per_transaction']:.1f}")
                    
                    st.markdown("---")
                    
                    # Generar recomendaciones usando cach√©
                    recommendations = get_cached_customer_recommendations(
                        customer_id=customer_id,
                        _transactions_df=transactions,
                        top_n=top_n,
                        top_k_similar=1000,
                        min_similarity=min_similarity
                    )
                    
                    if recommendations.empty:
                        st.warning("‚ö†Ô∏è No se encontraron productos para recomendar. Intenta ajustar los par√°metros.")
                    else:
                        st.markdown(f"### üéÅ Top {len(recommendations)} Productos Recomendados")
                        st.success(f"‚úÖ Se encontraron {len(recommendations)} recomendaciones basadas en clientes similares")
                        
                        # Mostrar tabla de recomendaciones
                        display_recommendations = recommendations[[
                            'product_id', 'product_name', 'category_name', 
                            'score', 'similar_customers_count'
                        ]].copy()
                        
                        display_recommendations = display_recommendations.rename(columns={
                            'product_id': 'ID Producto',
                            'product_name': 'Nombre',
                            'category_name': 'Categor√≠a',
                            'score': 'Score',
                            'similar_customers_count': 'Clientes que lo compraron'
                        })
                        
                        st.dataframe(
                            display_recommendations.style.format({
                                'Score': '{:.2f}'
                            }).background_gradient(subset=['Score'], cmap='Greens'),
                            width='stretch'
                        )
                        
                        # Gr√°fico de barras
                        fig = px.bar(
                            recommendations.head(10),
                            x='score',
                            y='product_name',
                            orientation='h',
                            title=f'Top 10 Productos Recomendados para Cliente {customer_id}',
                            labels={'score': 'Score de Recomendaci√≥n', 'product_name': 'Producto'},
                            color='score',
                            color_continuous_scale='Greens'
                        )
                        fig.update_layout(height=500, showlegend=False)
                        st.plotly_chart(fig, width='stretch')
                        
                        # Bot√≥n de descarga
                        csv = recommendations.to_csv(index=False)
                        st.download_button(
                            label="üì• Descargar Recomendaciones CSV",
                            data=csv,
                            file_name=f"recomendaciones_cliente_{customer_id}.csv",
                            mime="text/csv"
                        )
    
    else:  # Por Producto
        st.subheader("üè∑Ô∏è Recomendaciones Basadas en Producto")
        st.info(
            "üí° Este sistema utiliza **Market Basket Analysis** con reglas de asociaci√≥n (Apriori). "
            "Descubre qu√© productos se compran frecuentemente juntos."
        )
        
        # Inputs de configuraci√≥n
        col1, col2 = st.columns([2, 2])
        
        with col1:
            product_id = st.number_input(
                "ID del Producto",
                min_value=1,
                value=1,
                help="Ingresa el ID del producto para obtener recomendaciones"
            )
        
        with col2:
            top_n = st.number_input(
                "Top N",
                min_value=1,
                max_value=50,
                value=RecommenderConfig.TOP_N,
                help="N√∫mero de productos a recomendar",
                key="top_n_product"
            )
        
        # Par√°metros avanzados
        with st.expander("‚öôÔ∏è Configuraci√≥n Avanzada de Apriori"):
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                min_support = st.slider(
                    "Soporte M√≠nimo (%)",
                    min_value=0.1,
                    max_value=10.0,
                    value=RecommenderConfig.MIN_SUPPORT * 100,
                    step=0.1,
                    help="Porcentaje m√≠nimo de transacciones que contienen el itemset"
                ) / 100
            
            with col2:
                min_confidence = st.slider(
                    "Confianza M√≠nima (%)",
                    min_value=10.0,
                    max_value=100.0,
                    value=RecommenderConfig.MIN_CONFIDENCE * 100,
                    step=5.0,
                    help="Probabilidad de que se compre B dado que se compr√≥ A"
                ) / 100
            
            with col3:
                min_lift = st.slider(
                    "Lift M√≠nimo",
                    min_value=1.0,
                    max_value=10.0,
                    value=RecommenderConfig.MIN_LIFT,
                    step=0.1,
                    help="Cu√°nto m√°s probable es comprar B dado A vs. comprar B solo"
                )
            
            with col4:
                max_transactions_input = st.number_input(
                    "M√°x. Transacciones",
                    min_value=10000,
                    max_value=1200000,
                    value=RecommenderConfig.MAX_TRANSACTIONS,
                    step=10000,
                    help="N√∫mero m√°ximo de transacciones a analizar. Mayor = m√°s lento pero m√°s preciso"
                )
                # Convertir a None si es muy grande (para procesar todas)
                max_transactions = None if max_transactions_input >= 1000000 else max_transactions_input
            
            st.info(
                "üìä **M√©tricas explicadas:**\n"
                "- **Support**: Frecuencia de aparici√≥n del itemset\n"
                "- **Confidence**: P(B|A) - Probabilidad condicional\n"
                "- **Lift**: Indica qu√© tan fuerte es la asociaci√≥n (>1 = asociaci√≥n positiva)\n"
                "- **M√°x. Transacciones**: Usa sample aleatorio para acelerar an√°lisis. Valores recomendados: 50k (r√°pido), 100k (balance), 200k (preciso)"
            )
        
        # Bot√≥n para generar recomendaciones
        if st.button("üîç Generar Recomendaciones", type="primary", key="rec_product"):
            with st.spinner("Analizando patrones de compra y generando reglas de asociaci√≥n..."):
                # Obtener estad√≠sticas del producto
                product_stats = recommender.get_product_statistics(product_id, transactions)
                
                if not product_stats:
                    st.error(f"‚ùå Producto {product_id} no encontrado en los datos.")
                else:
                    # Mostrar informaci√≥n del producto
                    st.markdown("### üì¶ Informaci√≥n del Producto")
                    
                    st.markdown(f"**Nombre:** {product_stats['product_name']}")
                    st.markdown(f"**Categor√≠a:** {product_stats['category_name']}")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("Unidades Vendidas", f"{product_stats['total_quantity']:,}")
                    with col2:
                        st.metric("Clientes √önicos", f"{product_stats['unique_customers']:,}")
                    with col3:
                        st.metric("Transacciones", f"{product_stats['unique_transactions']:,}")
                    with col4:
                        st.metric("Cantidad Promedio", f"{product_stats['avg_quantity_per_transaction']:.2f}")
                    
                    st.markdown("---")
                    
                    # Generar recomendaciones usando cach√©
                    try:
                        # Construir reglas de asociaci√≥n (cacheadas)
                        association_rules = build_cached_association_rules(
                            _transactions_df=transactions,
                            min_support=min_support,
                            min_confidence=min_confidence,
                            min_lift=min_lift,
                            max_transactions=max_transactions
                        )
                        
                        # Obtener recomendaciones usando las reglas cacheadas
                        recommendations = get_cached_product_recommendations(
                            product_id=product_id,
                            _association_rules=association_rules,
                            _transactions_df=transactions,
                            top_n=top_n
                        )
                        
                        if recommendations.empty:
                            st.warning(
                                "‚ö†Ô∏è No se encontraron productos relacionados con los par√°metros actuales. "
                                "Intenta reducir los umbrales en la configuraci√≥n avanzada."
                            )
                        else:
                            st.markdown(f"### üõí Top {len(recommendations)} Productos que se Compran Juntos")
                            st.success(f"‚úÖ Se encontraron {len(recommendations)} productos frecuentemente comprados con este producto")
                            
                            # Mostrar tabla de recomendaciones
                            display_recommendations = recommendations[[
                                'product_id', 'product_name', 'category_name',
                                'score', 'lift', 'confidence', 'support'
                            ]].copy()
                            
                            display_recommendations = display_recommendations.rename(columns={
                                'product_id': 'ID Producto',
                                'product_name': 'Nombre',
                                'category_name': 'Categor√≠a',
                                'score': 'Score',
                                'lift': 'Lift',
                                'confidence': 'Confianza (%)',
                                'support': 'Soporte (%)'
                            })
                            
                            st.dataframe(
                                display_recommendations.style.format({
                                    'Score': '{:.2f}',
                                    'Lift': '{:.2f}',
                                    'Confianza (%)': '{:.2f}',
                                    'Soporte (%)': '{:.2f}'
                                }).background_gradient(subset=['Score'], cmap='Blues'),
                                width='stretch'
                            )
                            
                            # Gr√°fico de barras
                            fig = px.bar(
                                recommendations.head(10),
                                x='lift',
                                y='product_name',
                                orientation='h',
                                title=f'Top 10 Productos Asociados con {product_stats["product_name"]}',
                                labels={'lift': 'Lift', 'product_name': 'Producto'},
                                color='lift',
                                color_continuous_scale='Blues',
                                hover_data=['confidence', 'support']
                            )
                            fig.update_layout(height=500, showlegend=False)
                            st.plotly_chart(fig, width='stretch')
                            
                            # Bot√≥n de descarga
                            csv = recommendations.to_csv(index=False)
                            st.download_button(
                                label="üì• Descargar Recomendaciones CSV",
                                data=csv,
                                file_name=f"recomendaciones_producto_{product_id}.csv",
                                mime="text/csv"
                            )
                    
                    except Exception as e:
                        st.error(f"‚ùå Error al generar recomendaciones: {str(e)}")
                        logger.error(f"Error en recomendaciones: {e}", exc_info=True)


def main():
    """Punto de entrada principal de la aplicaci√≥n."""
    st.set_page_config(
        page_title="An√°lisis de Transacciones",
        page_icon="üõí",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("üõí An√°lisis de Transacciones de Supermercado")
    
    # Verificar si existen datos procesados
    data_exists = (Paths.DATA_PROCESSED / 'transactions_expanded.csv').exists()
    
    # Si no existen datos procesados, generarlos autom√°ticamente
    if not data_exists:
        st.info("üîÑ Primera ejecuci√≥n detectada. Procesando datos iniciales...")
        
        with st.spinner("‚è≥ Cargando y procesando datos originales... Esto puede tomar unos minutos."):
            try:
                # Crear directorio si no existe
                Paths.DATA_PROCESSED.mkdir(parents=True, exist_ok=True)
                
                # Ejecutar pipeline de procesamiento
                loader = DataLoader()
                processor = DataProcessor()
                
                # Cargar datos raw
                transactions_raw = loader.load_transactions()
                categories = loader.load_categories()
                product_category = loader.load_product_category()
                
                # Procesar todos los datos usando process_all
                processed_data = processor.process_all(transactions_raw, product_category, categories)
                
                # Guardar datos procesados
                processed_data['transactions_expanded'].to_csv(Paths.DATA_PROCESSED / 'transactions_expanded.csv', index=False)
                processed_data['customer_metrics'].to_csv(Paths.DATA_PROCESSED / 'customer_metrics.csv', index=False)
                processed_data['product_metrics'].to_csv(Paths.DATA_PROCESSED / 'product_metrics.csv', index=False)
                processed_data['transaction_metrics'].to_csv(Paths.DATA_PROCESSED / 'transaction_metrics.csv', index=False)
                
                st.success("‚úÖ Datos procesados correctamente!")
                st.rerun()
                
            except Exception as e:
                st.error(f"‚ùå Error al procesar datos iniciales: {str(e)}")
                logger.error(f"Error en procesamiento inicial: {e}", exc_info=True)
                st.stop()
    
    # Sidebar con navegaci√≥n
    st.sidebar.title("Navegaci√≥n")
    page = st.sidebar.radio(
        "Selecciona una p√°gina:",
        [
            "Dashboard Ejecutivo",
            "An√°lisis Temporal",
            "An√°lisis de Distribuciones",
            "An√°lisis de Correlaciones",
            "Segmentaci√≥n de Clientes",
            "Sistema de Recomendaci√≥n",
            "Carga de Nuevos Datos"
        ]
    )
    
    # Cargar datos procesados
    with st.spinner("Cargando datos..."):
        transactions, customer_metrics, product_metrics, transaction_metrics = load_processed_data()
    
    st.sidebar.markdown("---")
    
    # Filtros (solo para algunas p√°ginas)
    if page in ["Dashboard Ejecutivo", "An√°lisis Temporal"]:
        date_range, selected_store, selected_category = render_sidebar_filters(transactions)
        transactions_filtered = apply_filters(transactions, date_range, selected_store, selected_category)
    else:
        transactions_filtered = transactions
    
    # Renderizar p√°gina seleccionada
    if page == "Dashboard Ejecutivo":
        render_dashboard(transactions_filtered, customer_metrics, product_metrics)
    
    elif page == "An√°lisis Temporal":
        render_temporal_analysis(transactions_filtered)
    
    elif page == "An√°lisis de Distribuciones":
        render_distributions_analysis(customer_metrics, product_metrics)
    
    elif page == "An√°lisis de Correlaciones":
        render_correlations_analysis(customer_metrics)
    
    elif page == "Segmentaci√≥n de Clientes":
        render_customer_segmentation(customer_metrics)
    
    elif page == "Sistema de Recomendaci√≥n":
        render_recommendations(transactions)
    
    elif page == "Carga de Nuevos Datos":
        render_data_upload()


if __name__ == "__main__":
    main()
